{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "#from utils_laj import *\n",
    "from data_processing import get_SensorData, my_pca, series_to_supervised, lstm_sampling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost\n",
    "\n",
    "today = datetime.date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_checkpoint = './save/save_lstm/lstm_2_layers'\n",
    "input_path = './input_data'\n",
    "file = os.path.join(input_path,'sensors.csv')\n",
    "target_file = os.path.join(input_path,'coke_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считываем данные из файлов, нормализуем и применяем метод главных комполнентов\n",
    "X, y, submit_X, mean_y, std_y = get_SensorData(file, target_file, nc=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.159007111780772 0.5062311242891079\n"
     ]
    }
   ],
   "source": [
    "print(mean_y, std_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66839234 0.05001844 0.0454892  0.04043455 0.02760575 0.02430107\n",
      " 0.02172642 0.01984493 0.01803035 0.01471829] [0.66839234 0.71841079 0.76389998 0.80433454 0.83194029 0.85624136\n",
      " 0.87796778 0.89781272 0.91584307 0.93056136]\n"
     ]
    }
   ],
   "source": [
    "evals = pca.explained_variance_ratio_\n",
    "evals_cs = evals.cumsum()\n",
    "print(evals, evals_cs)\n",
    "# Кумулятивное variance_explained равно 93%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data X: (10400, 11), y (10400, 2), submit_X (13272, 11)\n"
     ]
    }
   ],
   "source": [
    "# Размерности датасета с известным целевым y и полного датасета\n",
    "print(\"Data X: %s, y %s, submit_X %s\" % (X.shape, y.shape, submit_X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Xl: (10200, 2010), yl (10200,)\n",
      "Data x_train: (7650, 2010), x_test: (2550, 2010), y_train (7650,), y_test (2550,)\n"
     ]
    }
   ],
   "source": [
    "# преобразование датасета для возможности supervised learning\n",
    "# используем для обучения и валидации модели данные за предыдущие 48 часов (time_length)\n",
    "time_length = 200\n",
    "Xl = series_to_supervised(X.iloc[:,1:len(list(X))], n_in=time_length, n_out=1)\n",
    "yl = y['target'][time_length:]\n",
    "print(\"Data Xl: %s, yl %s\" % (Xl.shape, yl.shape))\n",
    "# формируем данные конкурса по аналогичному принципу\n",
    "Xs = series_to_supervised(submit_X.iloc[Xl.shape[0]:,1:len(list(submit_X))], n_in=time_length, n_out=1)\n",
    "\n",
    "# выделим последние 25% в тестовый датасет\n",
    "x_train, x_test, y_train, y_test = train_test_split(Xl, yl, test_size=0.25, random_state=42, shuffle=False)\n",
    "print(\"Data x_train: %s, x_test: %s, y_train %s, y_test %s\" % (x_train.shape, x_test.shape, y_train.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"mygbm2.pkl\"\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "params = {'n_estimators': 1000, \n",
    "          'max_depth': 4, \n",
    "          'min_samples_split': 2,\n",
    "          'learning_rate': 0.001, \n",
    "          'loss': 'ls',\n",
    "          'verbose': 1}\n",
    "          \n",
    "my_gbm = GBR(**params)\n",
    "my_gbm.fit(x_train, y_train)\n",
    "s = pickle.dump(my_gbm, open(filename, 'wb'))\n",
    "#clf2 = pickle.loads(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_gbm = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = my_gbm.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.4341\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE: %.4f\" % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4341383818932758"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_gbm.loss_(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submit = my_gbm.predict(Xs)*std_y+mean_y\n",
    "sub_file = pd.DataFrame()\n",
    "sub_file[\"timestamp\"] = submit_X[\"timestamp\"][Xl.shape[0]+time_length:]\n",
    "sub_file[\"target\"] = y_submit\n",
    "sub_file.to_csv('submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
