{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "from utils_laj import *\n",
    "from data_processing import get_SensorData, my_pca, series_to_supervised, lstm_sampling\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "today = datetime.date.today()\n",
    "TR_END = \"2017-12-31 23:00:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_checkpoint = './save/save_lstm/lstm_2_layers'\n",
    "input_path = './input_data'\n",
    "file = os.path.join(input_path,'sensors.csv')\n",
    "target_file = os.path.join(input_path,'coke_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature shape: (13272, 48)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py:5434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target length: (10400, 2)\n",
      "Explained variance [0.50143148 0.12808438 0.06505652 0.04321608 0.03529743 0.0335428\n",
      " 0.02754238 0.0183814  0.01835391 0.0181078  0.01717936 0.0154992 ], Cumsum [0.50143148 0.62951587 0.69457238 0.73778846 0.77308589 0.80662869\n",
      " 0.83417107 0.85255247 0.87090638 0.88901418 0.90619354 0.92169274]\n"
     ]
    }
   ],
   "source": [
    "# Считываем данные из файлов, нормализуем и применяем метод главных комполнентов\n",
    "X, y, submit_X, mean_y, std_y = get_SensorData(file, target_file, nc=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data X: (10400, 12), y (10400, 2), submit_X (13272, 12)\n"
     ]
    }
   ],
   "source": [
    "# Размерности датасета с известным целевым y и полного датасета\n",
    "print(\"Data X: %s, y %s, submit_X %s\" % (X.shape, y.shape, submit_X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples length 7480\n",
      "Targets length 7480\n",
      "Samples length 2872\n",
      "Targets length 2872\n",
      "Samples length 13224\n",
      "Targets length 0\n",
      "Data x_train, y_train: ((7480, 48, 12),(7480, 48));  x_test, y_test: ((2872, 48, 12),(2872, 48)); Xs, ys: ((13224, 48, 12),None) \n"
     ]
    }
   ],
   "source": [
    "# выделим последние записи в размере контрольного датасета в тестовый датасет\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(X, y, test_size=2920, random_state=42, shuffle=False)\n",
    "\n",
    "# Формируем сэмплы для LSTM по 48 рядов внахлест с шагом 1\n",
    "timesteps = 48\n",
    "lag = 1\n",
    "i_train = len(x1_train) + timesteps  \n",
    "\n",
    "\n",
    "x_train, y_train = lstm_sampling(X[:i_train], y=y[:i_train]['target'], timesteps=timesteps, lag=lag)\n",
    "x_test, y_test = lstm_sampling(x1_test, y=y1_test['target'], timesteps=timesteps, lag=lag)\n",
    "#yl = y['target'][timesteps:]\n",
    "\n",
    "# формируем данные сабмита по аналогичному принципу + берем 47 шагов из тестовых данных\n",
    "Xs, ys = lstm_sampling(submit_X, timesteps=timesteps, lag=lag)\n",
    "\n",
    "print(\"Data x_train, y_train: (%s,%s);  x_test, y_test: (%s,%s); Xs, ys: (%s,%s) \" % (x_train.shape, y_train.shape, x_test.shape, y_test.shape, Xs.shape, ys))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    Train = True\n",
    "    Predict = True\n",
    "    plot = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    batch_size = 359  # Batch size\n",
    "    shift = batch_size\n",
    "    #if Train == False: batch_size = 1\n",
    "\n",
    "    sequence_length = timesteps  # Number of steps\n",
    "    learning_rate = 4*10e-5  # 0.0001\n",
    "    epochs = 1000\n",
    "    ann_hidden = 16\n",
    "\n",
    "    n_channels = x_train.shape[2]\n",
    "\n",
    "    lstm_size = 48  # Number LSTM units\n",
    "    num_layers = 3  # 2  # Number of layers\n",
    "    alpha = 0 # regularization coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Conv Shape: [None, 48, 12]\n"
     ]
    }
   ],
   "source": [
    "    X = tf.placeholder(tf.float32, [None, sequence_length, n_channels], name='inputs')\n",
    "    Y = tf.placeholder(tf.float32, [None, sequence_length], name='labels')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name='learning_rate')\n",
    "    is_train = tf.placeholder(dtype=tf.bool, shape=None, name=\"is_train\")\n",
    "\n",
    "    conv_last_layer = X\n",
    "\n",
    "    shape = conv_last_layer.get_shape().as_list()\n",
    "    print('My Conv Shape:',shape)\n",
    "    CNN_flat = tf.reshape(conv_last_layer, [-1, shape[1] * shape[2]])\n",
    "\n",
    "    dence_layer_1 = dense_layer(CNN_flat, size=sequence_length * n_channels, activation_fn=tf.nn.relu, batch_norm=False,\n",
    "                                phase=is_train, drop_out=True, keep_prob=keep_prob,\n",
    "                                scope=\"fc_1\")\n",
    "    lstm_input = tf.reshape(dence_layer_1, [-1, sequence_length, n_channels])\n",
    "\n",
    "    cell = get_RNNCell(['LSTM'] * num_layers, keep_prob=keep_prob, state_size=lstm_size)\n",
    "    init_states = cell.zero_state(batch_size, tf.float32)\n",
    "    \n",
    "    # For each layer, get the initial state. states will be a tuple of LSTMStateTuples.\n",
    "    states = get_state_variables(batch_size, cell)\n",
    "\n",
    "    # Unroll the LSTM\n",
    "    rnn_output, new_states = tf.nn.dynamic_rnn(cell, lstm_input, dtype=tf.float32, initial_state=states)\n",
    "    \n",
    "    # Add an operation to update the train states with the last state tensors.\n",
    "    update_op = get_state_update_op(states, new_states)\n",
    "    reset_op = get_state_update_op(states, init_states)\n",
    "    \n",
    "    stacked_rnn_output = tf.reshape(rnn_output, [-1, lstm_size])  # change the form into a tensor\n",
    "\n",
    "    dence_layer_2 = dense_layer(stacked_rnn_output, size=ann_hidden, activation_fn=tf.nn.relu, batch_norm=False,\n",
    "                                phase=is_train, drop_out=True, keep_prob=keep_prob,\n",
    "                                scope=\"fc_2\")\n",
    "    \n",
    "    dence_layer_3 = dense_layer(dence_layer_2, size=ann_hidden, activation_fn=tf.nn.relu, batch_norm=False,\n",
    "                                phase=is_train, drop_out=True, keep_prob=keep_prob,\n",
    "                                scope=\"fc_2_2\")\n",
    "\n",
    "    output = dense_layer(dence_layer_3, size=1, activation_fn=None, batch_norm=False, phase=is_train, drop_out=False,\n",
    "                         keep_prob=keep_prob,\n",
    "                         scope=\"fc_3_output\")\n",
    "\n",
    "    prediction = tf.reshape(output, [-1])\n",
    "    y_flat = tf.reshape(Y, [-1])\n",
    "\n",
    "    h = prediction - y_flat\n",
    "    \n",
    "    tv = tf.trainable_variables()\n",
    "    regularization_cost = tf.reduce_sum([ tf.nn.l2_loss(v) for v in tv ])\n",
    "\n",
    "    cost_function = tf.reduce_sum(tf.square(h)) + alpha*regularization_cost\n",
    "    RMSE = tf.sqrt(tf.reduce_mean(tf.square(h)))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost_function)\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    training_generator = batch_generator(x_train, y_train, batch_size, sequence_length, online=True, online_shift=shift)\n",
    "    testing_generator = batch_generator(x_test, y_test, batch_size, sequence_length, online=True, online_shift=shift)\n",
    "    #print(len(list(training_generator)))\n",
    "\n",
    "    if Train: model_summary(learning_rate=learning_rate, batch_size=batch_size, lstm_layers=num_layers,\n",
    "                            lstm_layer_size=lstm_size, fc_layer_size=ann_hidden, sequence_length=sequence_length,\n",
    "                            n_channels=n_channels, path_checkpoint=path_checkpoint, spacial_note='')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save/save_lstm/lstm_2_layers\n",
      "Training set MSE\n",
      "No epoches:  1000 No itr:  20\n",
      "LSTM epoch: 0 RMSE-train: 0.63644594 RMSE-test 0.57658833 lr 0.0004 \ttime/epoch: 4.24 \ttime_remaining:  1  hr: 10.7  min \ttime_stamp:  2018.11.15-18:45:00\n",
      "LSTM epoch: 1 RMSE-train: 0.61716336 RMSE-test 0.5729039 lr 0.0004 \ttime/epoch: 3.15 \ttime_remaining:  0  hr: 52.4  min \ttime_stamp:  2018.11.15-18:45:04\n",
      "LSTM epoch: 2 RMSE-train: 0.61926615 RMSE-test 0.5823159 lr 0.0004 \ttime/epoch: 3.14 \ttime_remaining:  0  hr: 52.3  min \ttime_stamp:  2018.11.15-18:45:07\n",
      "LSTM epoch: 3 RMSE-train: 0.6158336 RMSE-test 0.57483804 lr 0.0004 \ttime/epoch: 3.13 \ttime_remaining:  0  hr: 52.0  min \ttime_stamp:  2018.11.15-18:45:10\n",
      "LSTM epoch: 4 RMSE-train: 0.620839 RMSE-test 0.5832534 lr 0.0004 \ttime/epoch: 3.15 \ttime_remaining:  0  hr: 52.2  min \ttime_stamp:  2018.11.15-18:45:13\n",
      "LSTM epoch: 5 RMSE-train: 0.60860646 RMSE-test 0.5821167 lr 0.0004 \ttime/epoch: 3.14 \ttime_remaining:  0  hr: 52.1  min \ttime_stamp:  2018.11.15-18:45:16\n",
      "LSTM epoch: 6 RMSE-train: 0.6174749 RMSE-test 0.575186 lr 0.0004 \ttime/epoch: 3.18 \ttime_remaining:  0  hr: 52.8  min \ttime_stamp:  2018.11.15-18:45:19\n",
      "LSTM epoch: 7 RMSE-train: 0.6055874 RMSE-test 0.5856067 lr 0.0004 \ttime/epoch: 3.08 \ttime_remaining:  0  hr: 51.0  min \ttime_stamp:  2018.11.15-18:45:22\n",
      "LSTM epoch: 8 RMSE-train: 0.6132995 RMSE-test 0.5801147 lr 0.0004 \ttime/epoch: 3.13 \ttime_remaining:  0  hr: 51.8  min \ttime_stamp:  2018.11.15-18:45:26\n",
      "LSTM epoch: 9 RMSE-train: 0.6021411 RMSE-test 0.592203 lr 0.0004 \ttime/epoch: 3.07 \ttime_remaining:  0  hr: 50.7  min \ttime_stamp:  2018.11.15-18:45:29\n",
      "LSTM epoch: 10 RMSE-train: 0.60820746 RMSE-test 0.5906677 lr 0.0004 \ttime/epoch: 3.12 \ttime_remaining:  0  hr: 51.5  min \ttime_stamp:  2018.11.15-18:45:32\n",
      "LSTM epoch: 11 RMSE-train: 0.60764056 RMSE-test 0.5895784 lr 0.0004 \ttime/epoch: 3.17 \ttime_remaining:  0  hr: 52.2  min \ttime_stamp:  2018.11.15-18:45:35\n",
      "LSTM epoch: 12 RMSE-train: 0.6002486 RMSE-test 0.60618794 lr 0.0004 \ttime/epoch: 3.19 \ttime_remaining:  0  hr: 52.5  min \ttime_stamp:  2018.11.15-18:45:38\n",
      "LSTM epoch: 13 RMSE-train: 0.6183536 RMSE-test 0.59117055 lr 0.0004 \ttime/epoch: 3.12 \ttime_remaining:  0  hr: 51.3  min \ttime_stamp:  2018.11.15-18:45:41\n",
      "LSTM epoch: 14 RMSE-train: 0.59132075 RMSE-test 0.61120373 lr 0.0004 \ttime/epoch: 3.12 \ttime_remaining:  0  hr: 51.3  min \ttime_stamp:  2018.11.15-18:45:44\n",
      "LSTM epoch: 15 RMSE-train: 0.60994023 RMSE-test 0.5972187 lr 0.0004 \ttime/epoch: 3.17 \ttime_remaining:  0  hr: 52.1  min \ttime_stamp:  2018.11.15-18:45:48\n",
      "LSTM epoch: 16 RMSE-train: 0.5937593 RMSE-test 0.6120819 lr 0.0004 \ttime/epoch: 3.11 \ttime_remaining:  0  hr: 51.0  min \ttime_stamp:  2018.11.15-18:45:51\n",
      "LSTM epoch: 17 RMSE-train: 0.5979264 RMSE-test 0.6096524 lr 0.0004 \ttime/epoch: 3.21 \ttime_remaining:  0  hr: 52.6  min \ttime_stamp:  2018.11.15-18:45:54\n",
      "LSTM epoch: 18 RMSE-train: 0.59347475 RMSE-test 0.6102575 lr 0.0004 \ttime/epoch: 3.1 \ttime_remaining:  0  hr: 50.7  min \ttime_stamp:  2018.11.15-18:45:57\n",
      "LSTM epoch: 19 RMSE-train: 0.5954133 RMSE-test 0.6200291 lr 0.0004 \ttime/epoch: 3.17 \ttime_remaining:  0  hr: 51.9  min \ttime_stamp:  2018.11.15-18:46:00\n",
      "LSTM epoch: 20 RMSE-train: 0.6057183 RMSE-test 0.6097225 lr 0.0004 \ttime/epoch: 3.15 \ttime_remaining:  0  hr: 51.4  min \ttime_stamp:  2018.11.15-18:46:03\n",
      "LSTM epoch: 21 RMSE-train: 0.5860264 RMSE-test 0.6216503 lr 0.0004 \ttime/epoch: 3.15 \ttime_remaining:  0  hr: 51.4  min \ttime_stamp:  2018.11.15-18:46:06\n",
      "LSTM epoch: 22 RMSE-train: 0.6073644 RMSE-test 0.5987277 lr 0.0004 \ttime/epoch: 3.09 \ttime_remaining:  0  hr: 50.4  min \ttime_stamp:  2018.11.15-18:46:10\n",
      "LSTM epoch: 23 RMSE-train: 0.58487767 RMSE-test 0.6241148 lr 0.0004 \ttime/epoch: 3.2 \ttime_remaining:  0  hr: 52.0  min \ttime_stamp:  2018.11.15-18:46:13\n",
      "LSTM epoch: 24 RMSE-train: 0.6001085 RMSE-test 0.60368264 lr 0.0004 \ttime/epoch: 3.15 \ttime_remaining:  0  hr: 51.2  min \ttime_stamp:  2018.11.15-18:46:16\n",
      "LSTM epoch: 25 RMSE-train: 0.5928343 RMSE-test 0.6191258 lr 0.0004 \ttime/epoch: 3.13 \ttime_remaining:  0  hr: 50.9  min \ttime_stamp:  2018.11.15-18:46:19\n",
      "LSTM epoch: 26 RMSE-train: 0.584734 RMSE-test 0.6272154 lr 0.0004 \ttime/epoch: 3.04 \ttime_remaining:  0  hr: 49.3  min \ttime_stamp:  2018.11.15-18:46:22\n",
      "LSTM epoch: 27 RMSE-train: 0.6102036 RMSE-test 0.6110562 lr 0.0004 \ttime/epoch: 3.16 \ttime_remaining:  0  hr: 51.2  min \ttime_stamp:  2018.11.15-18:46:25\n",
      "LSTM epoch: 28 RMSE-train: 0.5763034 RMSE-test 0.63030916 lr 0.0004 \ttime/epoch: 3.16 \ttime_remaining:  0  hr: 51.2  min \ttime_stamp:  2018.11.15-18:46:28\n",
      "LSTM epoch: 29 RMSE-train: 0.6024571 RMSE-test 0.5964942 lr 0.0004 \ttime/epoch: 3.16 \ttime_remaining:  0  hr: 51.2  min \ttime_stamp:  2018.11.15-18:46:32\n",
      "LSTM epoch: 30 RMSE-train: 0.5847049 RMSE-test 0.6316643 lr 0.0004 \ttime/epoch: 3.1 \ttime_remaining:  0  hr: 50.0  min \ttime_stamp:  2018.11.15-18:46:35\n",
      "LSTM epoch: 31 RMSE-train: 0.5872809 RMSE-test 0.6045033 lr 0.0004 \ttime/epoch: 3.05 \ttime_remaining:  0  hr: 49.2  min \ttime_stamp:  2018.11.15-18:46:38\n",
      "LSTM epoch: 32 RMSE-train: 0.58487266 RMSE-test 0.6312126 lr 0.0004 \ttime/epoch: 3.12 \ttime_remaining:  0  hr: 50.4  min \ttime_stamp:  2018.11.15-18:46:41\n",
      "LSTM epoch: 33 RMSE-train: 0.5787565 RMSE-test 0.61021334 lr 0.0004 \ttime/epoch: 3.2 \ttime_remaining:  0  hr: 51.5  min \ttime_stamp:  2018.11.15-18:46:44\n",
      "LSTM epoch: 34 RMSE-train: 0.60048264 RMSE-test 0.62484676 lr 0.0004 \ttime/epoch: 3.16 \ttime_remaining:  0  hr: 50.9  min \ttime_stamp:  2018.11.15-18:46:47\n",
      "LSTM epoch: 35 RMSE-train: 0.5710712 RMSE-test 0.6341533 lr 0.0004 \ttime/epoch: 3.19 \ttime_remaining:  0  hr: 51.3  min \ttime_stamp:  2018.11.15-18:46:50\n",
      "LSTM epoch: 36 RMSE-train: 0.60835105 RMSE-test 0.59916717 lr 0.0004 \ttime/epoch: 3.17 \ttime_remaining:  0  hr: 50.9  min \ttime_stamp:  2018.11.15-18:46:54\n",
      "LSTM epoch: 37 RMSE-train: 0.5748223 RMSE-test 0.62828207 lr 0.0004 \ttime/epoch: 3.1 \ttime_remaining:  0  hr: 49.7  min \ttime_stamp:  2018.11.15-18:46:57\n",
      "LSTM epoch: 38 RMSE-train: 0.5872906 RMSE-test 0.60934913 lr 0.0004 \ttime/epoch: 3.12 \ttime_remaining:  0  hr: 50.1  min \ttime_stamp:  2018.11.15-18:47:00\n",
      "LSTM epoch: 39 RMSE-train: 0.57931566 RMSE-test 0.63427293 lr 0.0004 \ttime/epoch: 3.15 \ttime_remaining:  0  hr: 50.5  min \ttime_stamp:  2018.11.15-18:47:03\n",
      "LSTM epoch: 40 RMSE-train: 0.5734166 RMSE-test 0.6235666 lr 0.0004 \ttime/epoch: 3.11 \ttime_remaining:  0  hr: 49.8  min \ttime_stamp:  2018.11.15-18:47:06\n",
      "LSTM epoch: 41 RMSE-train: 0.60084426 RMSE-test 0.62582326 lr 0.0004 \ttime/epoch: 3.19 \ttime_remaining:  0  hr: 50.9  min \ttime_stamp:  2018.11.15-18:47:09\n",
      "LSTM epoch: 42 RMSE-train: 0.5720344 RMSE-test 0.6352249 lr 0.0004 \ttime/epoch: 3.19 \ttime_remaining:  0  hr: 51.0  min \ttime_stamp:  2018.11.15-18:47:12\n",
      "LSTM epoch: 43 RMSE-train: 0.5958847 RMSE-test 0.6104911 lr 0.0004 \ttime/epoch: 3.21 \ttime_remaining:  0  hr: 51.2  min \ttime_stamp:  2018.11.15-18:47:16\n",
      "LSTM epoch: 44 RMSE-train: 0.5753322 RMSE-test 0.6226866 lr 0.0004 \ttime/epoch: 3.22 \ttime_remaining:  0  hr: 51.4  min \ttime_stamp:  2018.11.15-18:47:19\n",
      "LSTM epoch: 45 RMSE-train: 0.5777619 RMSE-test 0.6430512 lr 0.0004 \ttime/epoch: 3.16 \ttime_remaining:  0  hr: 50.3  min \ttime_stamp:  2018.11.15-18:47:22\n",
      "LSTM epoch: 46 RMSE-train: 0.58569264 RMSE-test 0.62774795 lr 0.0004 \ttime/epoch: 3.19 \ttime_remaining:  0  hr: 50.7  min \ttime_stamp:  2018.11.15-18:47:25\n",
      "LSTM epoch: 47 RMSE-train: 0.56251055 RMSE-test 0.64537615 lr 0.0004 \ttime/epoch: 3.22 \ttime_remaining:  0  hr: 51.1  min \ttime_stamp:  2018.11.15-18:47:28\n",
      "LSTM epoch: 48 RMSE-train: 0.5903753 RMSE-test 0.61419 lr 0.0004 \ttime/epoch: 3.17 \ttime_remaining:  0  hr: 50.3  min \ttime_stamp:  2018.11.15-18:47:32\n",
      "LSTM epoch: 49 RMSE-train: 0.57321453 RMSE-test 0.6597402 lr 0.0004 \ttime/epoch: 3.11 \ttime_remaining:  0  hr: 49.2  min \ttime_stamp:  2018.11.15-18:47:35\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-400153a08a59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;31m#print(\"states:\",session.run(states))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 session.run([optimizer, update_op],\n\u001b[0;32m---> 28\u001b[0;31m                             feed_dict={X: batch_x, Y: batch_y, keep_prob: 0.7, learning_rate_: learning_rate})\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0mh_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    with tf.Session() as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        if Train == True:\n",
    "            saver.restore(session, path_checkpoint)\n",
    "            print(\"Model restored from file: %s\" % path_checkpoint)\n",
    "\n",
    "            cost = []\n",
    "            plot_x = []\n",
    "            plot_y1 = []\n",
    "            plot_y2 = []\n",
    "            iter_train = int(x_train.shape[0]/shift)\n",
    "            iter_test = int(x_test.shape[0]/shift)\n",
    "            print(\"Training set MSE\")\n",
    "            print(\"No epoches: \", epochs, \"No itr: \", iter_train)\n",
    "            __start = time.time()\n",
    "            for ep in range(epochs):\n",
    "                session.run(reset_op)\n",
    "                \n",
    "                h1 = []\n",
    "                t1 = []\n",
    "                   \n",
    "                for itr in range(iter_train):\n",
    "                    ## training ##\n",
    "                    batch_x, batch_y = next(training_generator)\n",
    "                    #print(\"states:\",session.run(states))\n",
    "                    session.run([optimizer, update_op],\n",
    "                                feed_dict={X: batch_x, Y: batch_y, keep_prob: 0.7, learning_rate_: learning_rate})\n",
    "                    h_i = h.eval(feed_dict={X: batch_x, Y: batch_y, keep_prob: 1.0, learning_rate_: learning_rate})\n",
    "                    cost.append(np.square(h_i))\n",
    "                    h1.append(h_i)\n",
    "\n",
    "                rmse_train = np.sqrt(np.mean(np.square(h1)))\n",
    "                \n",
    "                y_pred = []\n",
    "                for itr in range(iter_test):\n",
    "                    x_test_batch, y_test_batch = next(testing_generator)\n",
    "                    #print(\"states:\",session.run(states))\n",
    "                    h_i, u = session.run([h, update_op], feed_dict={X: x_test_batch, Y: y_test_batch, keep_prob: 1.0, learning_rate_: learning_rate})\n",
    "                    #session.run(update_op)\n",
    "                    t1.append(h_i)\n",
    "                \n",
    "                rmse_test = np.sqrt(np.mean(np.square(t1)))\n",
    "                \n",
    "                #rmse_train = session.run(RMSE, feed_dict={X: batch_x, Y: batch_y, keep_prob: 1.0})\n",
    "                rmse_test = session.run(RMSE, feed_dict={X: x_test_batch, Y: y_test_batch, keep_prob: 1.0})\n",
    "                plot_x.append(ep)\n",
    "                plot_y1.append(rmse_train)\n",
    "                plot_y2.append(rmse_test)\n",
    "                \n",
    "                #print(ep)\n",
    "\n",
    "                time_per_ep = (time.time() - __start)\n",
    "                time_remaining = ((epochs - ep) * time_per_ep) / 3600\n",
    "                print(\"LSTM\", \"epoch:\", ep, \"RMSE-train:\", rmse_train, \"RMSE-test\", rmse_test, \"lr\", learning_rate,\n",
    "                      \"\\ttime/epoch:\", round(time_per_ep, 2), \"\\ttime_remaining: \",\n",
    "                      int(time_remaining), \" hr:\", round((time_remaining % 1) * 60, 1), \" min\", \"\\ttime_stamp: \",\n",
    "                      datetime.datetime.now().strftime(\"%Y.%m.%d-%H:%M:%S\"))\n",
    "                __start = time.time()\n",
    "\n",
    "                if ep % 100 == 0 and ep != 0:\n",
    "                    save_path = saver.save(session, path_checkpoint)\n",
    "                    if os.path.exists(path_checkpoint + '.meta'):\n",
    "                        print(\"Model saved to file: %s\" % path_checkpoint)\n",
    "                    else:\n",
    "                        print(\"NOT SAVED!!!\", path_checkpoint)\n",
    "\n",
    "                if ep % 50 == 0 and ep != 0: \n",
    "                    plt.plot(plot_x, plot_y1, 'bo', plot_x, plot_y2, 'go')\n",
    "                    plt.show()\n",
    "                        \n",
    "                if ep % 400 == 0 and ep != 0: \n",
    "                    learning_rate = learning_rate / 2\n",
    "\n",
    "\n",
    "            save_path = saver.save(session, path_checkpoint)\n",
    "            if os.path.exists(path_checkpoint + '.meta'):\n",
    "                print(\"Model saved to file: %s\" % path_checkpoint)\n",
    "            else:\n",
    "                print(\"NOT SAVED!!!\", path_checkpoint)\n",
    "            plt.plot(plot_x, plot_y1, 'bo', plot_x, plot_y2, 'go')\n",
    "            plt.show()\n",
    "        else:\n",
    "            saver.restore(session, path_checkpoint)\n",
    "            print(\"Model restored from file: %s\" % path_checkpoint)\n",
    "            if Predict == True:\n",
    "                print(\"Prediction for submit...\")\n",
    "                x_predict = Xs\n",
    "                y_predict = np.zeros((Xs.shape[0],Xs.shape[1]))\n",
    "\n",
    "                predict_generator = batch_generator(x_predict, y_predict, batch_size, sequence_length,\n",
    "                                                       online=True, online_shift=shift)\n",
    "\n",
    "                full_prediction = []\n",
    "\n",
    "                iteration = int(x_predict.shape[0] / shift)\n",
    "                #print(\"iteration: %i, predgen %s\" % (iteration, predict_generator))\n",
    "                print(\"#of validation points:\", x_predict.shape[0], \"#datapoints covers from minibatch:\",\n",
    "                      batch_size * sequence_length, \"iterations/epoch\", iteration)\n",
    "\n",
    "                for itr in range(iteration):\n",
    "                    x_validate_batch, y_validate_batch = next(predict_generator)\n",
    "                    #print (itr)\n",
    "                    __y_pred, u = session.run([output, update_op], feed_dict={X: x_validate_batch, Y: y_validate_batch, keep_prob: 1.0})\n",
    "                    #session.run(update_op)\n",
    "                    for i in range(batch_size):\n",
    "                        full_prediction.append(__y_pred[i*sequence_length])\n",
    "                    #print(__y_pred.shape)\n",
    "                    \n",
    "                full_prediction = np.array(full_prediction)\n",
    "                full_prediction = full_prediction.ravel()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validate_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shft = x_train.shape[0]+x_test.shape[0]+sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(submit_X.index[shft:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submit = full_prediction*std_y+mean_y\n",
    "sub_file = pd.DataFrame()\n",
    "sub_file[\"timestamp\"] = submit_X.index[-2872:]\n",
    "sub_file[\"target\"] = y_submit[-2872:]\n",
    "sub_file.to_csv('submit2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LB 0.4705"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
